{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting TensorFlow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Frozen Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import array\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading ImageNet test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, ds_info = tfds.load('imagenet_v2', split='test', as_supervised=True, with_info=True)\n",
    "ds = tfds.as_numpy(ds)\n",
    "\n",
    "test_labels = []\n",
    "img_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for conversion and running model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TEST_SAMPLES = 100\n",
    "IMAGE_SIDE = 128\n",
    "\n",
    "def preprocess(image):\n",
    "    image = (image) / 127.5\n",
    "    return image - 1.0\n",
    "\n",
    "def imshow(img):\n",
    "    import cv2\n",
    "    import IPython\n",
    "    _,ret = cv2.imencode('.jpg', img) \n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)\n",
    "\n",
    "def quantizationDataGenerator():\n",
    "    count = 0\n",
    "    for image, label in ds:\n",
    "        image = image.copy()\n",
    "        image = cv2.resize(image, (IMAGE_SIDE, IMAGE_SIDE))\n",
    "        array = preprocess(image).astype(np.float32)[np.newaxis, ...]\n",
    "        yield([array])\n",
    "        count += 1\n",
    "        if count > 300:\n",
    "            break\n",
    "\n",
    "def testDataGenerator():\n",
    "    count = 0\n",
    "    for image, label in ds:\n",
    "        image = image.copy()\n",
    "        image = cv2.resize(image, (IMAGE_SIDE, IMAGE_SIDE))\n",
    "#         imshow(image)\n",
    "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite('img/' + str(label) + '.jpg', img_rgb, [cv2.IMWRITE_JPEG_QUALITY,100])\n",
    "#         print(img_rgb)\n",
    "        array = preprocess(image).astype(np.float32)[np.newaxis, ...]\n",
    "#         print(label)\n",
    "        test_labels.append(label)\n",
    "        yield(array)\n",
    "        count += 1\n",
    "        if count > 300:\n",
    "            break\n",
    "        \n",
    "def convertTFL(name, model):\n",
    "    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph('source_model/mobilenet_v1_0.5_128/mobilenet_v1_0.5_128_frozen.pb',\n",
    "                                                                    input_arrays = ['input'], output_arrays = ['MobilenetV1/Predictions/Reshape_1'], \n",
    "                                                                    input_shapes = {'input' : [1, IMAGE_SIDE, IMAGE_SIDE, 3]})\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = quantizationDataGenerator\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    quantModel = converter.convert()\n",
    "\n",
    "    with open(\"{}.tflite\".format(name), \"wb\") as f:\n",
    "        f.write(quantModel)\n",
    "        \n",
    "def runTFL(name):\n",
    "    from tflite_runtime.interpreter import Interpreter\n",
    "    interpreter = Interpreter('{}.tflite'.format(name))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    inputTensorIndex = interpreter.get_input_details()[0]['index']\n",
    "    outputTensorIndex = interpreter.get_output_details()[0]['index']\n",
    "    input_scale, input_zero_point = interpreter.get_input_details()[0]['quantization']\n",
    "    output_scale, output_zero_point = interpreter.get_output_details()[0]['quantization']\n",
    "\n",
    "    \n",
    "    prediction_values = []\n",
    "    \n",
    "    for x in testDataGenerator():\n",
    "        test_image = np.int8(x / input_scale + input_zero_point)\n",
    "        test_image = x\n",
    "        interpreter.set_tensor(inputTensorIndex, test_image)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(outputTensorIndex)\n",
    "        result = np.argmax(output[0])\n",
    "        prediction_values.append(result - 1)\n",
    "    \n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_values)):\n",
    "        print(str(prediction_values[index]) + \":\" + str(test_labels[index]))\n",
    "        if prediction_values[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_values)\n",
    "\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert and run TF Lite model to test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "name = 'mobilenet_v1'\n",
    "convertTFL(name, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model to test it on small dataset. \n",
    "Note: accuracy might be low on this specific data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runTFL(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to integrate converted model into TFLM application we have to save it as a C array. One way to do that is to use xxd utility available on Linux or in Cygwin/MinGW terminals on Windows. Open terminal and run following commands:\n",
    "\n",
    "```\n",
    "xxd -i mobilenet_v1.tflite > model.h\n",
    "```\n",
    "The model is ready to be integrated into TFLM application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
