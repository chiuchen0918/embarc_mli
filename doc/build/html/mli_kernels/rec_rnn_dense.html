

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>RNN Dense Prototype and Function List &mdash; embARC Machine Learning Library 2.0 2.00 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/style_overrides.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Basic Long Short Term Memory (LSTM) Cell Prototype and Function List" href="rec_lstm.html" />
    <link rel="prev" title="Fully Connected Prototype and Function List" href="rec_fully_con.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> embARC Machine Learning Library 2.0
          

          
          </a>

          
            
            
              <div class="version">
                2.00
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../whats_new/whats_new.html">What’s New in MLI 2.0 ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mli_api_data/mli_api_data.html">MLI API Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="mli_kernels.html">MLI Kernels (Operators)</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolution_grp.html">Convolution Kernels Group</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="rec_fully_con_grp.html">Recurrent and Fully Connected Kernels Group</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="rec_fully_con.html">Fully Connected Prototype and Function List</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">RNN Dense Prototype and Function List</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#functions">Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conditions">Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#result">Result</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rec_lstm.html">Basic Long Short Term Memory (LSTM) Cell Prototype and Function List</a></li>
<li class="toctree-l2"><a class="reference internal" href="rec_gru.html">Gated Recurrent Unit (GRU) Cell Prototype and Function List</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pooling_grp.html">Pooling Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="diverse_kernels_grp.html">Diverse Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="transform_grp.html">Transform (Activation) Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="elemw_grp.html">Element-wise Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_movement/data_movement.html">Data Movement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utility_functions/utility_functions.html">Utility Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platform_specific/platform_hint_sum.html">Platform Specific Details</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">embARC Machine Learning Library 2.0</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="rec_fully_con_grp.html">Recurrent and Fully Connected Kernels Group</a> &raquo;</li>
        
      <li>RNN Dense Prototype and Function List</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/mli_kernels/rec_rnn_dense.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="rnn-dense-prototype-and-function-list">
<h1>RNN Dense Prototype and Function List<a class="headerlink" href="#rnn-dense-prototype-and-function-list" title="Permalink to this headline">¶</a></h1>
<div class="section" id="description">
<h2>Description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h2>
<p>This kernel implements a single basic fully connected (or dense) calculation
typically used in the majority of RNN architectures:</p>
<div class="math notranslate nohighlight">
\[y_{i} = b_{i} + \sum_{j}^{}{xa}_{j}*{Wa}_{i,j} +
              \ \sum_{j}^{}{xb}_{j}*{Wb}_{i,j} +
                \ldots\ \sum_{j}^{}{xn}_{j}*{Wn}_{i,j}\]</div>
<p>Where:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\({xa}_{j}\)</span>, <span class="math notranslate nohighlight">\({xb}_{j}\)</span>, <span class="math notranslate nohighlight">\({xn}_{j}\)</span> <em>-</em>
<span class="math notranslate nohighlight">\(j_{\text{th}}\)</span> <em>value in one of the input tensors. These input
tensors might be current input, previous output, cell state or any other
tensor depending on RNN Cell architecture</em></p>
<p><span class="math notranslate nohighlight">\({Wa}_{i,j}\)</span>, <span class="math notranslate nohighlight">\({Wb}_{i,j}\)</span>, <span class="math notranslate nohighlight">\({Wc}_{i,j}\)</span> <em>- weight
of</em> <span class="math notranslate nohighlight">\(j_{th}\ \)</span><em>input element for</em>
<span class="math notranslate nohighlight">\(i_{th}\)</span> <em>neuron in one of input weights tensors. These
weights tensors might be input-to-a-gate weights, output-to-a-gate
weights or any other tensor depending on RNN Cell architecture</em></p>
<p><span class="math notranslate nohighlight">\(y_{i}\)</span> <em>- output of</em> <span class="math notranslate nohighlight">\(i_{th}\)</span> neuron
( <span class="math notranslate nohighlight">\(i_{th}\)</span> <em>value in output tensor).</em></p>
<p><span class="math notranslate nohighlight">\(b_{i}\)</span> <em>- bias for</em> <span class="math notranslate nohighlight">\(i_{th}\)</span> <em>neuron</em></p>
</div></blockquote>
<p>This is a MAC-based kernel which implies accumulation. See <a class="reference internal" href="../mli_api_data/data_formats.html#quant-accum-infl"><span class="std std-ref">Quantization: Influence of Accumulator Bit Depth</span></a> for more information on related quantization aspects.
The number of accumulation series is equal to total number of values in all inputs.</p>
</div>
<div class="section" id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h2>
<p>Kernels which implement an RNN Dense functionality have the following prototype:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">mli_status</span> <span class="n">mli_krn_rnn_dense_</span><span class="o">&lt;</span><span class="n">data_format</span><span class="o">&gt;</span><span class="p">(</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">**</span><span class="n">weights</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">bias</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_rnn_dense_cfg</span> <span class="o">*</span><span class="n">cfg</span><span class="p">,</span>
   <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">out</span><span class="p">);</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">data_format</span></code> is one of the data formats listed in Table <a class="reference internal" href="../mli_api_data/data_formats.html#mli-data-fmts"><span class="std std-ref">MLI Data Formats</span></a> and the
function parameters are shown in the following table:</p>
<table class="colwidths-auto docutils align-center" id="id1">
<caption><span class="caption-text">RNN Dense Function Parameters</span><a class="headerlink" href="#id1" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Parameter</strong></p></th>
<th class="head"><p><strong>Type</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">**</span></code></p></td>
<td><p>[IN] Pointer to the array of pointers to constant input tensors</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">weights</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">**</span></code></p></td>
<td><p>[IN] Pointer to the array of pointers to constant weights tensors</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">bias</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant bias tensor</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cfg</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_rnn_dense_cfg</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to RNN dense parameters structure</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">out</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN | OUT] Pointer to output tensor. Result is stored here.</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><p><code class="code docutils literal notranslate"><span class="pre">mli_rnn_dense_cfg</span></code> is defined as:</p>
</div></blockquote>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="k">typedef</span> <span class="k">struct</span> <span class="p">{</span>
     <span class="kt">uint8_t</span> <span class="n">inputs_num</span><span class="p">;</span>
 <span class="p">}</span> <span class="n">mli_rnn_dense_cfg</span><span class="p">;</span>
</pre></div>
</div>
<span id="t-mli-rnn-dense-cfg-desc"></span><table class="docutils align-center" id="id2">
<caption><span class="caption-text">mli_rnn_dense_cfg Structure Field Description</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 19%" />
<col style="width: 15%" />
<col style="width: 66%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Field Name</strong></p></th>
<th class="head"><p><strong>Type</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">inputs_num</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">uint8_t</span></code></p></td>
<td><p>Number of input tensors (number of pointers in inputs
array). Also, the number of weights tensors (number of
pointers in weights   array), as each input is specified
with its own weights tensor. Maximum number of tensors
in the array is specified by MLI_RNN_MAX_INPUTS define.</p></td>
</tr>
</tbody>
</table>
<p>Here is a list of all available RNN Dense functions:</p>
<table class="colwidths-auto docutils align-center" id="id3">
<caption><span class="caption-text">List of Available RNN Dense Functions</span><a class="headerlink" href="#id3" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Function Name</strong></p></th>
<th class="head"><p><strong>Details</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_rnn_dense_sa8_sa8_sa32</span></code></p></td>
<td><p>In/out/weights data format: <strong>sa8</strong></p>
<p>Bias data format: <strong>sa32</strong></p>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_rnn_dense_fx16</span></code></p></td>
<td><p>All tensors data format: <strong>fx16</strong></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_rnn_dense_fx16_fx8_fx8</span></code></p></td>
<td><p>In/out data format: <strong>fx16</strong></p>
<p>Weights/Bias data format: <strong>fx8</strong></p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="conditions">
<h2>Conditions<a class="headerlink" href="#conditions" title="Permalink to this headline">¶</a></h2>
<p>Ensure that you satisfy the following general conditions before calling the listed functions:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code>, all tensors in <code class="docutils literal notranslate"><span class="pre">inputs</span></code> array and all tensors in <code class="docutils literal notranslate"><span class="pre">weights</span></code> array
must be valid (see <a class="reference internal" href="../mli_api_data/data_structures.html#mli-tnsr-struc"><span class="std std-ref">mli_tensor Structure Field Descriptions</span></a>).</p></li>
<li><p>The number of tensors in <code class="docutils literal notranslate"><span class="pre">inputs</span></code> and <code class="docutils literal notranslate"><span class="pre">weights</span></code> arrays must be the same and
must not exceed <code class="docutils literal notranslate"><span class="pre">MLI_RNN_MAX_INPUTS</span></code> value.</p></li>
<li><p>Shapes of <code class="docutils literal notranslate"><span class="pre">bias</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code>, all tensors in <code class="docutils literal notranslate"><span class="pre">inputs</span></code> array and all tensors in <code class="docutils literal notranslate"><span class="pre">weights</span></code>
array must be compatible, which implies the following requirements:</p>
<ul class="simple">
<li><p>Each tensor in <code class="docutils literal notranslate"><span class="pre">inputs</span></code> array might be of any shape and rank. Only total
number of elements is considered.</p></li>
<li><p>The <span class="math notranslate nohighlight">\(i_{th}\)</span> tensor in <code class="docutils literal notranslate"><span class="pre">weights</span></code> array corresponds to the <span class="math notranslate nohighlight">\(i_{th}\)</span> tensor in
<code class="docutils literal notranslate"><span class="pre">inputs</span></code> array, which means that <code class="docutils literal notranslate"><span class="pre">weights[i]</span></code> must be a two-dimensional tensor (rank==2) of shape
<span class="math notranslate nohighlight">\((N_i, M)\)</span>, where <span class="math notranslate nohighlight">\(N_i\)</span> is the total number of elements in the <code class="docutils literal notranslate"><span class="pre">inputs[i]</span></code> tensor
and <span class="math notranslate nohighlight">\(M\)</span> is the total number of neurons and is equal to output length.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code> must be a one-dimensional tensor (rank==1). Its length must be equal to <span class="math notranslate nohighlight">\(M\)</span> (number
of filters and is equal to output length) of any weights tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">out</span></code> must be a one-dimensional tensor (rank==1). Its length must be equal to <span class="math notranslate nohighlight">\(M\)</span> (number
of filters and is equal to output length) of any weights tensor.</p></li>
</ul>
</li>
<li><p>Any tensor from <code class="docutils literal notranslate"><span class="pre">inputs</span></code> array and <code class="docutils literal notranslate"><span class="pre">out</span></code> tensor must not point to overlapped memory regions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mem_stride</span></code> must satisfy the following statements:</p>
<blockquote>
<div><ul class="simple">
<li><p>For <code class="docutils literal notranslate"><span class="pre">out</span></code> tensor and all tensors in <code class="docutils literal notranslate"><span class="pre">inputs</span></code> array memstride must reflect the shape,
e.g memory of these tensors must be contiguous.</p></li>
<li><p>For all tensors in <code class="docutils literal notranslate"><span class="pre">weights</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> arrays - memstride of the innermost dimension must
be equal to 1.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>For <strong>fx16</strong> and <strong>fx16_fx8_fx8</strong> versions of kernel, in addition to the general conditions, ensure that you
satisfy the following quantization conditions before calling the function:</p>
<blockquote>
<div><ul class="simple">
<li><p>The number of <code class="docutils literal notranslate"><span class="pre">frac_bits</span></code> in the <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensor must not exceed the sum of <code class="docutils literal notranslate"><span class="pre">frac_bits</span></code>
in the <code class="docutils literal notranslate"><span class="pre">inputs[0]</span></code> and <code class="docutils literal notranslate"><span class="pre">weights[0]</span></code> tensors.</p></li>
<li><p>The number of <code class="docutils literal notranslate"><span class="pre">frac_bits</span></code> in the <code class="docutils literal notranslate"><span class="pre">out</span></code> tensor must not exceed the sum of <code class="docutils literal notranslate"><span class="pre">frac_bits</span></code>
in the any pair of related tensors in <code class="docutils literal notranslate"><span class="pre">inputs</span></code> and <code class="docutils literal notranslate"><span class="pre">weights</span></code> arrays.</p></li>
</ul>
</div></blockquote>
<p>For <strong>sa8_sa8_sa32</strong> versions of kernel, in addition to the general conditions, ensure that you
satisfy the following quantization conditions before calling the function:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code>, all the tensors in <code class="docutils literal notranslate"><span class="pre">inputs</span></code> array, and all tensors in <code class="docutils literal notranslate"><span class="pre">weights</span></code> array
must be quantized on the tensor level. This implies that each tensor contains a
single scale factor and a single zero offset.</p></li>
<li><p>Zero offset of each tensor in inputs and out tensor must be within [-128, 127] range.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code> and all tensors in weights array must be symmetric. This implies that both
tensors contain single zero offset equal to 0.</p></li>
<li><p>The scale factor of <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensor must be equal to the multiplication of the scale factor of
the <strong>first</strong> input and the <strong>first</strong> weights tensors in corresponding arrays
(that is, <span class="math notranslate nohighlight">\(bias.scale = inputs[0].scale * weights[0].scale\)</span>). See the example for the
similar condition in the <a class="reference internal" href="conv_2d.html#conv-2d"><span class="std std-ref">Convolution 2D Prototype and Function List</span></a>.</p></li>
</ul>
</div></blockquote>
<p>Ensure that you satisfy the platform-specific conditions in addition to those listed above
(see the <a class="reference internal" href="../platform_specific/platform_hint_sum.html#platform-spec-chptr"><span class="std std-ref">Platform Specific Details</span></a> chapter).</p>
</div>
<div class="section" id="result">
<h2>Result<a class="headerlink" href="#result" title="Permalink to this headline">¶</a></h2>
<p>These functions only modify the memory pointed by <code class="docutils literal notranslate"><span class="pre">out.data.mem</span></code> field.
It is assumed that all the other fields of <code class="docutils literal notranslate"><span class="pre">out</span></code> tensor are properly populated
to be used in calculations and are not modified by the kernel.</p>
<p>Depending on the debug level (see section <a class="reference internal" href="../mli_api_data/error_codes.html#err-codes"><span class="std std-ref">Error Codes</span></a>), this function performs a parameter
check and returns the result as an <code class="docutils literal notranslate"><span class="pre">mli_status</span></code> code as described in section <a class="reference internal" href="../mli_api_data/data_structures.html#kernl-sp-conf"><span class="std std-ref">Kernel Specific Configuration Structures</span></a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="rec_lstm.html" class="btn btn-neutral float-right" title="Basic Long Short Term Memory (LSTM) Cell Prototype and Function List" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="rec_fully_con.html" class="btn btn-neutral float-left" title="Fully Connected Prototype and Function List" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2021, Synopsys, Inc

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>