

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Gated Recurrent Unit (GRU) Cell Prototype and Function List &mdash; embARC Machine Learning Library 2.0 2.00 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/style_overrides.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pooling Kernels Group" href="pooling_grp.html" />
    <link rel="prev" title="Basic Long Short Term Memory (LSTM) Cell Prototype and Function List" href="rec_lstm.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> embARC Machine Learning Library 2.0
          

          
          </a>

          
            
            
              <div class="version">
                2.00
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../whats_new/whats_new.html">What’s New in MLI 2.0 ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mli_api_data/mli_api_data.html">MLI API Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="mli_kernels.html">MLI Kernels (Operators)</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolution_grp.html">Convolution Kernels Group</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="rec_fully_con_grp.html">Recurrent and Fully Connected Kernels Group</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="rec_fully_con.html">Fully Connected Prototype and Function List</a></li>
<li class="toctree-l2"><a class="reference internal" href="rec_rnn_dense.html">RNN Dense Prototype and Function List</a></li>
<li class="toctree-l2"><a class="reference internal" href="rec_lstm.html">Basic Long Short Term Memory (LSTM) Cell Prototype and Function List</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Gated Recurrent Unit (GRU) Cell Prototype and Function List</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#functions">Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conditions">Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#result">Result</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pooling_grp.html">Pooling Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="diverse_kernels_grp.html">Diverse Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="transform_grp.html">Transform (Activation) Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="elemw_grp.html">Element-wise Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_movement/data_movement.html">Data Movement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utility_functions/utility_functions.html">Utility Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platform_specific/platform_hint_sum.html">Platform Specific Details</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">embARC Machine Learning Library 2.0</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="rec_fully_con_grp.html">Recurrent and Fully Connected Kernels Group</a> &raquo;</li>
        
      <li>Gated Recurrent Unit (GRU) Cell Prototype and Function List</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/mli_kernels/rec_gru.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="gated-recurrent-unit-gru-cell-prototype-and-function-list">
<h1>Gated Recurrent Unit (GRU) Cell Prototype and Function List<a class="headerlink" href="#gated-recurrent-unit-gru-cell-prototype-and-function-list" title="Permalink to this headline">¶</a></h1>
<div class="section" id="description">
<h2>Description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h2>
<p>This kernel implements the Gated Recurrent Unit (GRU) cell in version where a reset
gate is applied on the hidden state before matrix multiplication (see <a class="reference external" href="https://en.wikipedia.org/wiki/Gated_recurrent_unit">Depth-Gated Recurrent
Neural Networks</a> for more details),
as shown in Figure <a class="reference internal" href="#f-gru-schematic"><span class="std std-ref">Gated Recurrent Unit Schematic Representation</span></a>.</p>
<div class="figure align-center" id="id1">
<span id="f-gru-schematic"></span><img alt="../_images/gru_schematic.png" src="../_images/gru_schematic.png" />
<p class="caption"><span class="caption-text">Gated Recurrent Unit Schematic Representation</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>The GRU operation is described by the following formulas:</p>
<div class="math notranslate nohighlight" id="equation-eq-gru-op">
<span class="eqno">(1)<a class="headerlink" href="#equation-eq-gru-op" title="Permalink to this equation">¶</a></span>\[ \begin{align}\begin{aligned}{z_{t}} &amp;= {sigm\left( x_{t}W_{\text{xz}} + h_{t - 1}W_{\text{hz}} + b_{z} \right)}\\{r_{t}} &amp;= {sigm\left( x_{t}W_{\text{xr}} + h_{t - 1}W_{\text{hr}} + b_{r} \right)}\\{{\widetilde{h}}_{t}} &amp;= {tanh\left( x_{t}W_{\text{xu}} + (r_{t}*h_{t - 1})W_{\text{hu}} + b_{e} \right)}\\{h_{t}} &amp;= {z_{t}*h_{t - 1} + \left( 1 - z_{t} \right) *{\widetilde{h}}_{t}}\end{aligned}\end{align} \]</div>
<p>Where:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\ x_{t}\ \)</span> <em>- frame</em> <span class="math notranslate nohighlight">\(t\)</span> <em>in input sequence.</em></p>
<p><span class="math notranslate nohighlight">\(\ h_{t}\ \)</span> <em>- hidden state (also cell output) for frame</em>
<span class="math notranslate nohighlight">\(t\)</span> <em>in input sequence.</em></p>
<p><span class="math notranslate nohighlight">\(\ {\widetilde{h}}_{t}\ \)</span> <em>- updated hidden state for frame</em>
<span class="math notranslate nohighlight">\(t\)</span> <em>in input sequence.</em></p>
<p><span class="math notranslate nohighlight">\(z_{t}\ ,\ r_{t}\)</span> <em>- Update and reset gates subtensors for
frame</em> <span class="math notranslate nohighlight">\(t\)</span> <em>in input sequence.</em></p>
<p><span class="math notranslate nohighlight">\(W_{**}\ \)</span> <em>- weights for appropriate input subtensor.</em></p>
<p><span class="math notranslate nohighlight">\(b_{*}\ \)</span> <em>- bias for appropriate input subtensor.</em></p>
<p><span class="math notranslate nohighlight">\(sigm\)</span> , <span class="math notranslate nohighlight">\(tanh\)</span> <em>- sigmoid and hyperbolic tangent
activation functions.</em></p>
</div></blockquote>
<p>In the Figure <a class="reference internal" href="#f-gru-schematic"><span class="std std-ref">Gated Recurrent Unit Schematic Representation</span></a>, N is the total number of elements in the input and M is the total number
of elements in the cell output.</p>
<p>This kernel uses two look-up tables (LUTs) to perform data transformation.
See <a class="reference internal" href="trans_lut.html#lut-prot"><span class="std std-ref">Look-Up Tables (LUT) Manipulation Prototypes and Function List</span></a> section and the pseudo-code sample for more details on LUT structure preparation.
Use the following functions for the purpose:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">mli_krn_tanh_get_lut_size</span></code></p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">mli_krn_tanh_create_lut</span></code></p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">mli_krn_sigm_get_lut_size</span></code></p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">mli_krn_sigm_create_lut</span></code></p></li>
</ul>
</div></blockquote>
<p>This is a MAC-based kernel which implies accumulation. See <a class="reference internal" href="../mli_api_data/data_formats.html#quant-accum-infl"><span class="std std-ref">Quantization: Influence of Accumulator Bit Depth</span></a> for more information on related quantization aspects.
The number of accumulation series is equal to single input frame size plus single output frame size.</p>
</div>
<div class="section" id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h2>
<p>Kernels which implement an GRU cell have the following prototype:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">mli_status</span> <span class="n">mli_krn_gru_cell_</span><span class="o">&lt;</span><span class="n">data_format</span><span class="o">&gt;</span><span class="p">(</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">in</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">prev_out</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">weights_in</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">weights_out</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">bias</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_lut</span> <span class="o">*</span> <span class="n">tanh_lut</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_lut</span> <span class="o">*</span> <span class="n">sigm_lut</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_rnn_cell_cfg</span> <span class="o">*</span><span class="n">cfg</span><span class="p">,</span>
   <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">out</span><span class="p">);</span>
</pre></div>
</div>
<p>where data_format is one of the data formats listed in Table <a class="reference internal" href="../mli_api_data/data_formats.html#mli-data-fmts"><span class="std std-ref">MLI Data Formats</span></a> and the function parameters
are shown in the following table:</p>
<table class="colwidths-auto docutils align-center" id="id2">
<caption><span class="caption-text">GRU Cell Function Parameters</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Parameter</strong></p></th>
<th class="head"><p><strong>Type</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">in</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant input tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">prev_out</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant previous output tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">weights_in</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant weights tensor for GRU input.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">weights_out</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant weights tensor for GRU output.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">bias</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant bias tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">tanh_lut</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_lut</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to a valid LUT table structure prepared
for the hyperbolic tangent activation.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sigm_lut</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_lut</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to a valid LUT table structure prepared for
the sigmoid  activation.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cfg</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_rnn_cell_cfg</span> <span class="pre">*</span></code></p></td>
<td><p>[IN | OUT] Pointer to RNN cell parameters structure.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">out</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN | OUT] Pointer to output tensor. Result is stored here.</p></td>
</tr>
</tbody>
</table>
<p>Fields of <code class="docutils literal notranslate"><span class="pre">mli_rnn_cell_cfg</span></code> structure are described in table <a class="reference internal" href="rec_fully_con_grp.html#t-mli-rnn-cell-cfg-desc"><span class="std std-ref">mli_rnn_cell_cfg Structure Field Description</span></a>.</p>
<p>Weights for the cell consist of two tensors:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">weights_in</span></code>: a three-dimensional tensor of shape (3, N, M) where N is a number of elements in
input tensor, and M is a number of elements in hidden state (equal to number of elements in
output tensor). It represents stacking of weights using the GRU operation <a class="reference internal" href="#equation-eq-gru-op">(1)</a> in order (z, r, u):</p></li>
</ul>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix}
W_{\text{xz}} &amp; W_{\text{xr}} &amp; W_{\text{xu}} \\
\end{bmatrix}\end{split}\]</div>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">weights_out</span></code>: a three-dimensional tensor of shape (3, M, M) where M is a number of cell elements
(weights which involved into a single dot product series are stored column wise, that is, with M stride
in memory). It represents stacking of weights using the GRU operation <a class="reference internal" href="#equation-eq-gru-op">(1)</a> in order (z, r, u):</p></li>
</ul>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix}
W_{\text{hz}} &amp; W_{\text{hr}} &amp; W_{\text{hu}} \\
\end{bmatrix}\end{split}\]</div>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code> tensor of shape (3, M) keeps subtensors in the same order:</p></li>
</ul>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix}
b_{z} &amp; b_{r} &amp; b_{u} \\
\end{bmatrix}\end{split}\]</div>
<p>This kernel implies sequential processing of the set of inputs vectors (or timesteps) which is passed by input tensor
of shape (sequence_length, N) where N is the length of the single frame <span class="math notranslate nohighlight">\(x_{t}\)</span> . Both
directions of processing (forward and backward) are supported and defined by cfg structure. The Kernel can
output the bunch of results for according to each step of processing, or only the last one in the sequence.</p>
<p>Dense part of calculations uses scratch data from configuration structure for results, and consequently
output and previous output tensors might use the same memory if it is acceptable to rewrite previous
output data. Ensure that you allocate memory for the rest of the tensors and for scratch data from cfg
structure without overlaps. Otherwise the behavior is undefined.</p>
<p>The following table lists all the available GRU cell functions:</p>
<table class="colwidths-auto docutils align-center" id="id3">
<caption><span class="caption-text">List of Available GRU Cell Functions</span><a class="headerlink" href="#id3" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Function Name</strong></p></th>
<th class="head"><p><strong>Details</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_gru_cell_sa8_sa8_sa32</span></code></p></td>
<td><p>In/out/weights data format: <strong>sa8</strong></p>
<p>Bias data format: <strong>sa32</strong></p>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_gru_cell_fx16</span></code></p></td>
<td><p>All tensors data format: <strong>fx16</strong></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_gru_cell_fx16_fx8_fx8</span></code></p></td>
<td><p>In/out data format: <strong>fx16</strong></p>
<p>weights/Bias data format: <strong>fx8</strong></p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="conditions">
<h2>Conditions<a class="headerlink" href="#conditions" title="Permalink to this headline">¶</a></h2>
<p>Ensure that you satisfy the following general conditions before calling the function:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">in</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code>, <code class="docutils literal notranslate"><span class="pre">prev_out</span></code>, <code class="docutils literal notranslate"><span class="pre">weights_in</span></code>, <code class="docutils literal notranslate"><span class="pre">weights_out</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code>
tensors must be valid (see <a class="reference internal" href="../mli_api_data/data_structures.html#mli-tnsr-struc"><span class="std std-ref">mli_tensor Structure Field Descriptions</span></a>) and satisfy data requirements of the
selected version of the kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tanh_lut</span></code> and <code class="docutils literal notranslate"><span class="pre">sigm_lut</span></code> structures must be valid and prepared for
hyperbolic tangent and sigmoid activation functions accordingly (see <a class="reference internal" href="trans_lut.html#lut-prot"><span class="std std-ref">Look-Up Tables (LUT) Manipulation Prototypes and Function List</span></a>).</p></li>
<li><p>Shapes of <code class="docutils literal notranslate"><span class="pre">in</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code>, <code class="docutils literal notranslate"><span class="pre">prev_out</span></code>, <code class="docutils literal notranslate"><span class="pre">weights_in</span></code>, <code class="docutils literal notranslate"><span class="pre">weights_out</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code>
tensors must be compatible, which implies the following requirements:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">in</span></code> must be a 2-dimensional tensor (rank==2) of shape (sequence_length, <span class="math notranslate nohighlight">\(N\)</span>)
where sequence_length is a number of input frames (or timesteps) for sequential processing by GRU cell.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights_in</span></code> must be a 3-dimensional tensor (rank==3) of shape (3, <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(M\)</span>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights_out</span></code> must be a 3-dimensional tensor (rank==3) of shape (3, <span class="math notranslate nohighlight">\(M\)</span>, <span class="math notranslate nohighlight">\(M\)</span>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code> must be a 2-dimensional tensor (rank==2) of shape (3, <span class="math notranslate nohighlight">\(M\)</span>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prev_out</span></code> must be a one-dimensional tensor (rank==1) of shape (<span class="math notranslate nohighlight">\(M\)</span>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">out</span></code> tensor might be of any shape and rank. Kernel changes its shape to (sequence_length, <span class="math notranslate nohighlight">\(M\)</span>)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">out.data</span></code> container must point to a buffer with sufficient capacity for storing the result (to keep <span class="math notranslate nohighlight">\(M\)</span>
elements if GRU cell is configured with <code class="docutils literal notranslate"><span class="pre">RNN_OUT_LAST</span></code> or to keep <span class="math notranslate nohighlight">\(M*sequence\_length\)</span> elements if
GRU cell is configured with <code class="docutils literal notranslate"><span class="pre">RNN_OUT_ALL</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scratch_data</span></code> field in config structure must contain a valid pointer to a buffer with sufficient
capacity for the intermediate result (<span class="math notranslate nohighlight">\(3*M\)</span> elements of input type). The <code class="docutils literal notranslate"><span class="pre">capacity</span></code> field of
the <code class="docutils literal notranslate"><span class="pre">scratch_data</span></code> must reflect the available size of this memory in bytes properly
(see Table <a class="reference internal" href="rec_fully_con_grp.html#t-mli-rnn-cell-cfg-desc"><span class="std std-ref">mli_rnn_cell_cfg Structure Field Description</span></a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">in.data</span></code> and <code class="docutils literal notranslate"><span class="pre">cfg-&gt;scratch_data</span></code> containers must not point to overlapped memory regions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mem_stride</span></code> must satisfy the following statements:</p>
<blockquote>
<div><ul class="simple">
<li><p>For <code class="docutils literal notranslate"><span class="pre">in</span></code>, <code class="docutils literal notranslate"><span class="pre">prev_out</span></code> and <code class="docutils literal notranslate"><span class="pre">out</span></code> tensors - memstride must reflect the shape,
e.g memory of these tensors must be contiguous</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">weights_in</span></code>, <code class="docutils literal notranslate"><span class="pre">weights_out</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensor - memstride of the innermost dimension must
be equal to 1.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>For <strong>fx16</strong> and <strong>fx16_fx8_fx8</strong> versions of kernel, in addition to the general conditions, ensure that you
satisfy the following quantization conditions before calling the function:</p>
<blockquote>
<div><ul class="simple">
<li><p>The number of <code class="docutils literal notranslate"><span class="pre">frac_bits</span></code> in the <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensor must not exceed the sum of <code class="docutils literal notranslate"><span class="pre">frac_bits</span></code>
in the <code class="docutils literal notranslate"><span class="pre">in</span></code> and <code class="docutils literal notranslate"><span class="pre">weights_in</span></code> tensors.</p></li>
</ul>
</div></blockquote>
<p>For <strong>sa8_sa8_sa32</strong> versions of kernel, in addition to the general conditions, ensure that you
satisfy the following quantization conditions before calling the function:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">in</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code> and <code class="docutils literal notranslate"><span class="pre">prev_out</span></code> tensor must be quantized on the tensor level. This implies that each tensor
contains a single scale factor and a single zero offset.</p></li>
<li><p>Zero offset of <code class="docutils literal notranslate"><span class="pre">in</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code> and <code class="docutils literal notranslate"><span class="pre">prev_out</span></code> tensors must be within [-128, 127] range.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights_in</span></code>, <code class="docutils literal notranslate"><span class="pre">weights_out</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensors must be symmetric. All these tensors must be
quantized on the same level. Allowed Options:</p>
<ul>
<li><p>Per Tensor level. This implies that each tensor contains a single scale factor and a single
zero offset equal to 0.</p></li>
<li><p>Per First Dimension level (number of sub-tensors equal to 3). This implies that each tensor
contains separate scale point for each sub-tensor. All tensors contain single zero offset
equal to 0.</p></li>
</ul>
</li>
<li><p>Scale factors of <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensor must be equal to the multiplication of <code class="docutils literal notranslate"><span class="pre">in</span></code> scale factor
broadcasted on <code class="docutils literal notranslate"><span class="pre">weights_in</span></code> array of scale factors. See the example for the similar condition
in the <a class="reference internal" href="conv_2d.html#conv-2d"><span class="std std-ref">Convolution 2D Prototype and Function List</span></a>.</p></li>
</ul>
</div></blockquote>
<p>Ensure that you satisfy the platform-specific conditions in addition to those listed above
(see the <a class="reference internal" href="../platform_specific/platform_hint_sum.html#platform-spec-chptr"><span class="std std-ref">Platform Specific Details</span></a> chapter).</p>
</div>
<div class="section" id="result">
<h2>Result<a class="headerlink" href="#result" title="Permalink to this headline">¶</a></h2>
<p>These functions modify:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">shape</span></code>, <code class="docutils literal notranslate"><span class="pre">rank</span></code> and <code class="docutils literal notranslate"><span class="pre">mem_stride</span></code> of <code class="docutils literal notranslate"><span class="pre">out</span></code> tensor.</p></li>
<li><p>memory pointed by <code class="docutils literal notranslate"><span class="pre">out.data.mem</span></code> field.</p></li>
<li><p>memory pointed by <code class="docutils literal notranslate"><span class="pre">cfg.scratch_data.mem</span></code> fields.</p></li>
</ul>
</div></blockquote>
<p>It is assumed that all the other fields and structures are properly populated
to be used in calculations and are not modified by the kernel.</p>
<p>Depending on the debug level (see section <a class="reference internal" href="../mli_api_data/error_codes.html#err-codes"><span class="std std-ref">Error Codes</span></a>) this function performs a parameter
check and returns the result as an <code class="docutils literal notranslate"><span class="pre">mli_status</span></code> code as described in section <a class="reference internal" href="../mli_api_data/data_structures.html#kernl-sp-conf"><span class="std std-ref">Kernel Specific Configuration Structures</span></a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="pooling_grp.html" class="btn btn-neutral float-right" title="Pooling Kernels Group" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="rec_lstm.html" class="btn btn-neutral float-left" title="Basic Long Short Term Memory (LSTM) Cell Prototype and Function List" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2021, Synopsys, Inc

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>