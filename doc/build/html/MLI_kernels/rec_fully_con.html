

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Fully Connected Prototype and Function List &mdash; embARC Machine Learning Library 2.0 2.00 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/style_overrides.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="RNN Dense Prototype and Function List" href="rec_rnn_dense.html" />
    <link rel="prev" title="Recurrent and Fully Connected Kernels Group" href="rec_fully_con_grp.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> embARC Machine Learning Library 2.0
          

          
          </a>

          
            
            
              <div class="version">
                2.00
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../whats_new/whats_new.html">What’s New in MLI 2.0 ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mli_api_data/mli_api_data.html">MLI API Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="mli_kernels.html">MLI Kernels (Operators)</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolution_grp.html">Convolution Kernels Group</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="rec_fully_con_grp.html">Recurrent and Fully Connected Kernels Group</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Fully Connected Prototype and Function List</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#functions">Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conditions">Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#result">Result</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rec_rnn_dense.html">RNN Dense Prototype and Function List</a></li>
<li class="toctree-l2"><a class="reference internal" href="rec_lstm.html">Basic Long Short Term Memory (LSTM) Cell Prototype and Function List</a></li>
<li class="toctree-l2"><a class="reference internal" href="rec_gru.html">Gated Recurrent Unit (GRU) Cell Prototype and Function List</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pooling_grp.html">Pooling Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="diverse_kernels_grp.html">Diverse Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="transform_grp.html">Transform (Activation) Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="elemw_grp.html">Element-wise Kernels Group</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_movement/data_movement.html">Data Movement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utility_functions/utility_functions.html">Utility Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platform_specific/platform_hint_sum.html">Platform Specific Details</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">embARC Machine Learning Library 2.0</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="rec_fully_con_grp.html">Recurrent and Fully Connected Kernels Group</a> &raquo;</li>
        
      <li>Fully Connected Prototype and Function List</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/mli_kernels/rec_fully_con.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="fully-connected-prototype-and-function-list">
<span id="fully-con-grp"></span><h1>Fully Connected Prototype and Function List<a class="headerlink" href="#fully-connected-prototype-and-function-list" title="Permalink to this headline">¶</a></h1>
<div class="section" id="description">
<h2>Description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h2>
<div class="figure align-center" id="f-fully-conn-layer">
<img alt="../_images/fully_conn_layer.png" src="../_images/fully_conn_layer.png" />
</div>
<p>This kernel implements a fully connected layer, also usually referred to as the inner
product or dense layer.</p>
<p>Each value of output tensor is calculated according to the following formula:</p>
<div class="math notranslate nohighlight">
\[y_{i} = b_{i} + \sum_{j}^{}x_{j}*W_{i,j}\]</div>
<p>Where:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(x_{j}\)</span> <em>-</em> <span class="math notranslate nohighlight">\(j_{\text{th}}\)</span> <em>value in input tensor</em></p>
<p><span class="math notranslate nohighlight">\(y_{i}\)</span> <em>- output of</em> <span class="math notranslate nohighlight">\(i_{\text{th}}\)</span> neuron
(<span class="math notranslate nohighlight">\(i_{\text{th}}\)</span> <em>value in output tensor)</em></p>
<p><span class="math notranslate nohighlight">\(W_{i,j}\)</span> <em>- weight of</em> <span class="math notranslate nohighlight">\(j_{\text{th}}\ \)</span><em>input element
for</em> <span class="math notranslate nohighlight">\(i_{\text{th}}\)</span> <em>neuron.</em></p>
<p><span class="math notranslate nohighlight">\(b_{i}\)</span> <em>- bias for</em> <span class="math notranslate nohighlight">\(i_{\text{th}}\)</span> <em>neuron</em></p>
</div></blockquote>
<p>Optionally, a saturating ReLU activation function can be applied to the result of the calculations
during the function’s execution. For more information on supported ReLU types, see <a class="reference internal" href="trans_relu.html#relu-prot"><span class="std std-ref">ReLU Prototype and Function List</span></a>.</p>
<p>This is a MAC-based kernel which implies accumulation. See <a class="reference internal" href="../mli_api_data/data_formats.html#quant-accum-infl"><span class="std std-ref">Quantization: Influence of Accumulator Bit Depth</span></a> for more information on related quantization aspects.
The Number of accumulation series is equal to input size.</p>
</div>
<div class="section" id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h2>
<p>Functions that implement fully connected kernels have the following prototype:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">mli_status</span> <span class="n">mli_krn_fully_connected_</span><span class="o">&lt;</span><span class="n">data_format</span><span class="o">&gt;</span><span class="p">(</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">in</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">weights</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">bias</span><span class="p">,</span>
   <span class="k">const</span> <span class="n">mli_fully_connected_cfg</span> <span class="o">*</span><span class="n">cfg</span><span class="p">,</span>
   <span class="n">mli_tensor</span> <span class="o">*</span><span class="n">out</span><span class="p">);</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">data_format</span></code> is one of the data formats listed in Table <a class="reference internal" href="../mli_api_data/data_formats.html#mli-data-fmts"><span class="std std-ref">MLI Data Formats</span></a>
and the function parameters are shown in the following table:</p>
<table class="colwidths-auto docutils align-center" id="id1">
<caption><span class="caption-text">Fully Connected Function Parameters</span><a class="headerlink" href="#id1" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Parameter</strong></p></th>
<th class="head"><p><strong>Type</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">in</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant input tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">weights</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant weights tensor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">bias</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to constant bias tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cfg</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_fully_connected_cfg</span> <span class="pre">*</span></code></p></td>
<td><p>[IN] Pointer to fully connected parameters structure.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">out</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_tensor</span> <span class="pre">*</span></code></p></td>
<td><p>[IN | OUT] Pointer to output tensor. Result is stored here.</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">mli_fully_connected_cfg</span></code> is defined as:</p>
</div></blockquote>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="k">typedef</span> <span class="k">struct</span> <span class="p">{</span>
     <span class="n">mli_relu_cfg</span> <span class="n">relu</span><span class="p">;</span>
<span class="p">}</span> <span class="n">mli_fully_connected</span> <span class="n">cfg</span><span class="p">;</span>
</pre></div>
</div>
<span id="t-mli-fc-cfg-desc"></span><table class="docutils align-center" id="id2">
<caption><span class="caption-text">mli_fully_connected_cfg Structure field description</span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 18%" />
<col style="width: 22%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Field Name</strong></p></th>
<th class="head"><p><strong>Type</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">relu</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mli_relu_cfg</span></code></p></td>
<td><p>Type of ReLU activation applied to output values.
See <a class="reference internal" href="trans_relu.html#relu-prot"><span class="std std-ref">ReLU Prototype and Function List</span></a> for definition of this structure</p></td>
</tr>
</tbody>
</table>
<p>Here is a list of all available Fully Connected functions:</p>
<table class="docutils align-center" id="id3">
<caption><span class="caption-text">List of Available Fully Connected Functions</span><a class="headerlink" href="#id3" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 57%" />
<col style="width: 43%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Function Name</strong></p></th>
<th class="head"><p><strong>Details</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_fully_connected_sa8_sa8_sa32</span></code></p></td>
<td><p>In/out/weights data format: <strong>sa8</strong></p>
<p>Bias data format: <strong>sa32</strong></p>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_fully_connected_fx16</span></code></p></td>
<td><p>All tensors data format: <strong>fx16</strong></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_fully_connected_fx16_fx8_fx8</span></code></p></td>
<td><p>In/out data format: <strong>fx16</strong></p>
<p>Weights/Bias data format: <strong>fx8</strong></p>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mli_krn_fully_connected_sa8_sa8_sa32_ext_bias</span></code></p></td>
<td><p>In/out/weights data format: <strong>sa8</strong></p>
<p>Bias data format: <strong>sa32</strong></p>
<p>Bias data adjusted to include</p>
<p>zero point additives</p>
</td>
</tr>
</tbody>
</table>
<p><code class="docutils literal notranslate"><span class="pre">mli_krn_fully_connected_sa8_sa8_sa32_ext_bias</span></code> is a specialized version of
<code class="docutils literal notranslate"><span class="pre">mli_krn_fully_connected_sa8_sa8_sa32</span></code> which performs calculations much faster, but requires bias
data to be adjusted according to the following formula:</p>
<div class="math notranslate nohighlight">
\[\hat{b}_{i} = b_{i} + \sum_{j}^{}in\_zp*W_{i,j}\]</div>
<p>Where:</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(in\_zp\)</span> <em>-</em> zero point of input sa8 tensor</p>
<p><span class="math notranslate nohighlight">\(W_{i,j}\)</span> <em>- weight of</em> <span class="math notranslate nohighlight">\(j_{\text{th}}\ \)</span><em>input element
for</em> <span class="math notranslate nohighlight">\(i_{\text{th}}\)</span> <em>neuron.</em></p>
<p><span class="math notranslate nohighlight">\(b_{i}\)</span> <em>- original sa32 bias for</em> <span class="math notranslate nohighlight">\(i_{\text{th}}\)</span> <em>neuron</em></p>
<p><span class="math notranslate nohighlight">\(\hat{b}_{i}\)</span> <em>- adjusted sa32 bias for</em> <span class="math notranslate nohighlight">\(i_{\text{th}}\)</span> <em>neuron</em></p>
</div></blockquote>
</div>
<div class="section" id="conditions">
<h2>Conditions<a class="headerlink" href="#conditions" title="Permalink to this headline">¶</a></h2>
<p>Ensure that you satisfy the following general conditions before calling the function:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">in</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code>, <code class="docutils literal notranslate"><span class="pre">weights</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensors must be valid (see <a class="reference internal" href="../mli_api_data/data_structures.html#mli-tnsr-struc"><span class="std std-ref">mli_tensor Structure Field Descriptions</span></a>)
and satisfy data requirements of the selected version of the kernel.</p></li>
<li><p>Shapes of <code class="docutils literal notranslate"><span class="pre">in</span></code>, <code class="docutils literal notranslate"><span class="pre">out</span></code>, <code class="docutils literal notranslate"><span class="pre">weights</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensors must be compatible,
which implies the following requirements:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">in</span></code> tensor might be of any shape and rank. Only total number of elements is
considered.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights</span></code> is a 2-dimensional tensor (rank==2) of shape <span class="math notranslate nohighlight">\((N, M)\)</span>, where
<span class="math notranslate nohighlight">\(N\)</span> is the total number of elements in the input tensor and <span class="math notranslate nohighlight">\(M\)</span>
is the total number of neurons and is equal to output length.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code> must be a one-dimensional tensor (rank==1). Its length must be equal to
<span class="math notranslate nohighlight">\(M\)</span> dimension (number of filters and is equal to output length) of weights tensor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">out</span></code> must be a one-dimensional tensor (rank==1). Its length must be equal to
<span class="math notranslate nohighlight">\(M\)</span> dimension (number of filters) of weights tensor.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">in</span></code> and <code class="docutils literal notranslate"><span class="pre">out</span></code> tensors must not point to overlapped memory regions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mem_stride</span></code> must satisfy the following statements:</p>
<blockquote>
<div><ul class="simple">
<li><p>For <code class="docutils literal notranslate"><span class="pre">in</span></code> and <code class="docutils literal notranslate"><span class="pre">out</span></code> tensors - memstride must reflect the shape,
e.g memory of these tensors must be contiguous.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">weights</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensor - memstride of the innermost dimension must
be equal to 1.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>For <strong>fx16</strong> and <strong>fx16_fx8_fx8</strong> versions of kernel, in addition to the general conditions, ensure that you
satisfy the following quantization conditions before calling the function:</p>
<blockquote>
<div><ul class="simple">
<li><p>The number of <code class="docutils literal notranslate"><span class="pre">frac_bits</span></code> in the <code class="docutils literal notranslate"><span class="pre">bias</span></code> and <code class="docutils literal notranslate"><span class="pre">out</span></code> tensors must not exceed the sum of <code class="docutils literal notranslate"><span class="pre">frac_bits</span></code>
in the <code class="docutils literal notranslate"><span class="pre">in</span></code> and <code class="docutils literal notranslate"><span class="pre">weights</span></code> tensors.</p></li>
</ul>
</div></blockquote>
<p>For <strong>sa8_sa8_sa32</strong> versions of kernel, in addition to the general conditions, ensure that you
satisfy the following quantization conditions before calling the function:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">in</span></code> and  <code class="docutils literal notranslate"><span class="pre">out</span></code> tensors must be quantized on the tensor level.
It implies that each tensor contains a single scale factor and a single zero offset.</p></li>
<li><p>Zero offset of <code class="docutils literal notranslate"><span class="pre">in</span></code> and <code class="docutils literal notranslate"><span class="pre">out</span></code> tensors must be within [-128, 127] range.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> tensors must be symmetric. Both must be quantized at the same level.
Allowed options are</p>
<blockquote>
<div><ul class="simple">
<li><p>Per Tensor level. This implies that each tensor contains a single scale factor and a single zero
offset equal to 0.</p></li>
<li><p>Per <span class="math notranslate nohighlight">\(M\)</span> dimension level (number of neurons). This implies that each tensor contains separate scale point
for each sub-tensor. All tensors contain single zero offset equal to 0.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Scale factors of bias tensor must be equal to the multiplication of input scale factor
broadcasted on weights array of scale factors. See the example for the similar condition
in the <a class="reference internal" href="conv_2d.html#conv-2d"><span class="std std-ref">Convolution 2D Prototype and Function List</span></a>.</p></li>
</ul>
</div></blockquote>
<p>Ensure that you satisfy the platform-specific conditions in addition to those listed above
(see the <a class="reference internal" href="../platform_specific/platform_hint_sum.html#platform-spec-chptr"><span class="std std-ref">Platform Specific Details</span></a> chapter).</p>
</div>
<div class="section" id="result">
<h2>Result<a class="headerlink" href="#result" title="Permalink to this headline">¶</a></h2>
<p>These functions only modify the memory pointed by <code class="docutils literal notranslate"><span class="pre">out.data.mem</span></code> field.
It is assumed that all the other fields of <code class="docutils literal notranslate"><span class="pre">out</span></code> tensor are properly populated
to be used in calculations and are not modified by the kernel.</p>
<p>Depending on the debug level (see section <a class="reference internal" href="../mli_api_data/error_codes.html#err-codes"><span class="std std-ref">Error Codes</span></a>) this function performs a parameter
check and returns the result as an <code class="docutils literal notranslate"><span class="pre">mli_status</span></code> code as described in section <a class="reference internal" href="../mli_api_data/data_structures.html#kernl-sp-conf"><span class="std std-ref">Kernel Specific Configuration Structures</span></a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="rec_rnn_dense.html" class="btn btn-neutral float-right" title="RNN Dense Prototype and Function List" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="rec_fully_con_grp.html" class="btn btn-neutral float-left" title="Recurrent and Fully Connected Kernels Group" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2021, Synopsys, Inc

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>